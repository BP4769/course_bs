---
title: "Survey sampling basics"
author: Jure Demšar and Erik Štrumbelj, University of Ljubljana
output:
    prettydoc::html_pretty:
      highlight: github
      theme: architect
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align="center")
```

# Summary

In this chapter we focus on the basics of sampling in the context of survey sampling. We cover three of the most common probability sampling approaches: simple random sampling, stratified sampling, and cluster sampling. We also briefly discuss non-probability sampling methods: convenience sampling, judgment sampling, quota sampling, and snowball sampling.

# Introduction

Sampling consists of selecting a subset of units from our study population (or data generating process) for the purpose of generalizing the results obtained on this subset to the entire study population. 

Even those of us not familiar with survey sampling are likely to have encountered sampling in randomized algorithms, for example, random forests, or resampling methods, such as cross-validation and bootstrap. The underlying principles are the same as in survey sampling, as is the main reason for applying sampling -- sampling is typically used as a means to reduce the resources required for the enquiry. In random forests and bootstrap the resources we are trying to reduce are computational, but survey sampling is more complex, because time, money, human, and other resources have to be considered.

Sampling methods can be divided into two fundamentally different groups: probability sampling and non-probability sampling. In probability sampling every unit population has a non-zero probability of being selected and that probability is known. Non-probability sampling approaches violate at least one of those two criteria, some units can't be selected or are selected in a way such that the probability of their selection is not known. Simple random sampling is an example of probability sampling, while convenience sampling - for example, selecting units that are close at hand -- is an example of non-probability sampling.

The main characteristic of these two groups of approaches to sampling is that in probability sampling we can, using the laws of probability, derive the uncertainty in our results. In other words, we can quantify how representative the sample is of our population. In non-probability sampling, however, that is not possible, at least not without making additional assumptions.

The key component of sampling is the *sampling frame*. The sampling frame is a list of all units in the study population. In other words, it defines a set of units from which a researcher can select a sample of the study population. Without a sampling frame, probability sampling is not possible. However, in cases where our study population has a hierarchical structure, we can avoid the need for a detailed sampling frame for parts of the study population that were not selected at the higher level. We will discuss this in more detail in the Cluster sampling scheme.

In practice, if resources permit, probability sampling is always preferred over non-probability sampling. However, even when in situations where we can use probability sampling, the application is rarely ideal. Two main issues we face are coverage and non-response:

* Coverage: Ideally, our sampling frame would cover the entire study population. However, in practice, the sampling frame often does not include all units of the study population (under-coverage) or it includes some units that are not in the study population (over-coverage). For example, if we survey University of Ljubljana (UL) students, we might, if we are not careful, include non-UL students that are only spending a semester here (over-coverage), but miss UL students that are studying abroad this semester (under-coverage).

* Non-response: In practice, not all units can be measured. In particular, when dealing with human participants, not all participants will respond. Non-response is essentially a missing values problem.

Both coverage and non-response introduce bias into our results. In general, dealing with these issues requires careful consideration and the gathering of additional information. We will discuss non-response bias it in more detail in a later chapter. In this chapter we will, unless noted otherwise, assume that there are no coverage or non-response issues. In other words, the only source of uncertainty will be the sampling itself.

# Probability sampling schemes

Probability sampling approaches can be further subdivided into fixed-size/random-sized sample approaches and equal-probability/unequal-probability approaches. Equal-probability approaches are those where every unit has the same probability of being selected (simple random sampling) as opposed to having different inclusion probabilities (stratified sampling, cluster sampling). A fixed-size sample approach is, as the name suggests, one where the sample size is fixed and known. In this chapter we will only discuss fixed-size sample approaches. A prototypical random-sized sample approach is Poisson sampling, where each unit has a non-zero and potentially different probability of being selected. Poisson sampling is not common in practice, with the exception of surveys where there is a need to coordinate between samples - for example, where we want less or more overlap between two samples drawn from the same population. Poisson sampling is also introduced indirectly by non-response.

In all of our analyses we will focus on estimating the mean. The basic principles are the same for other quantities of interest, but each requires a different model.

The dataset that we will use throughout is an export of the football player database from the popular computer game Football Manager, we obtained the dataset from [Kaggle](https://www.kaggle.com/ajinkyablaze/football-manager-data).

```{r include=FALSE}
n  <- 200  # sample size
m  <- 100 # number of simulations
df <- readRDS("FM2017.rds")
df <- df[complete.cases(df),]
df$BestPosition <- names(df)[75:89][apply(df[,75:89],1, function(x){which(x == max(x))[1]})]
df <- df[, names(df) %in% c("Name", "NationID", "Age", "Height", "Weight", "BestPosition", "PenaltyTaking")]
df$BestPosition[df$BestPosition == "WingBackLeft"] <- "DefenderLeft"
df$BestPosition[df$BestPosition == "WingBackRight"] <- "DefenderRight"
df$BestPosition[df$BestPosition == "Sweeper"] <- "DefenderCentral"
true_mean <- mean(df$PenaltyTaking)
true_sd   <- sd(df$PenaltyTaking)
```

The dataset contains basic player information and ability estimates for `r nrow(df)` footballers. We will use only a subset of the columns and we will focus on estimating the mean of the Penalty Taking ability of footballers (between 1 - worst and 20 - best):

```{r echo = FALSE}
print(head(df, 10))
```

We will pretend that these footballers are our entire study population. Hence, the true mean $\mu_0 =$ `r round(true_mean, 2)` and true standard deviation $\sigma_0 =$ `r round(true_sd, 2)` of Penalty Taking are known. We will try to estimate this true mean via samples of fixed size $n =$ `r n`.

## Simple random sampling

Simple random sampling is a fixed-sized sample probability sampling scheme with equal inclusion probabilities. In other words, we sample $n$ samples uniformly at random.

True to its name, this is the simplest probability sampling scheme and when interested in the mean, we can invoke the LLN/CLT that say that the sample average will converge almost surely to the true mean `r round(true_sd, 2)` and the error will be approximately normally distributed with standard deviation $\frac{\sigma_0}{\sqrt{n}} =$ `r round(true_sd / sqrt(n), 3)`.

Let us simulate the process of drawing our $n =$ `r n` samples `r m` times to check if that is indeed the case:

```{r echo=FALSE, warning=FALSE, fig.width=2, fig.height=2}
library(ggplot2)

# simple random sampling
mus <- c()
set.seed(0)
for (i in 1:m) {
  idx <- sample(1:nrow(df), n, rep = T)
  mus <- c(mus, mean(df$PenaltyTaking[idx]))
}

ggplot(data.frame(mu = mus), aes(x = mu)) + geom_histogram(bins = 30) + 
  ylab("freq") + xlab("estimate")
```

The estimate of course varies from sample to sample. The average over all estimates is `r round(mean(mus), 2)` and their standard deviation (hence, standard error of the mean estimates) is `r round(sd(mus), 3)`. Both of these values are within margin of error of what we predicted from theory.

Simple random sampling is indeed simple but also very effective. The main reason why we would not use simple random sampling is that we do not have a sampling frame or we cannot execute it due to resource constraints. Also, if we have additional information about our units, other sampling schemes, such as stratified sampling, will be more effective.

### Bayesian estimation

```{r echo=FALSE, warning=FALSE, message=FALSE, results = 'hide'}
library(rstan)
ml     <- readLines("./simple.Stan")
model1 <- stan_model(model_code = ml)

set.seed(0)
res <- NULL
for (i in 1:20) {
  idx <- sample(1:nrow(df), n, rep = T)
  stan_data <- list(y = df$PenaltyTaking[idx], n = n)
  samples   <- sampling(model1, stan_data, chains = 1, iter = 1000)
  mus <- extract(samples)$mu
  res <- rbind(res, data.frame(mu = mean(mus), sd = sd(mus)))
}

```


## Stratified sampling

Stratification is a very simple idea and one that we might have already encountered in approaches such as stratified cross-validation, which is itself an example of stratified sampling. We partition the population into non-overlapping partitions called strata. We proceed by probability sampling each stratum independently of other strata. The final sample is a union of all samples. Note that any sampling scheme can be used to sample from each stratum, even stratified sampling, but in our analyses we will assume that simple random sampling is used.

When using stratified sampling, we have to allocate our total number of samples to individual strata. We will discuss two popular approaches: *proportional allocation* and *optimal allocation*.

Let $k$ be the number of strata and $N_i$, $n_i$ be the size of and the number of samples allocated to the $i-$th strata, respectively. Let $w_i = \frac{n_i}{n}$ be the weights of allocation. We must have $\sum_{i=1}^k n_i = n$, which implies that the weights sum to 1.

In *proportional allocation* we assign $n_i$ so that $w_i = \frac{N_i}{\sum_{i=1}^k N_i}$. That is, that each strata is allocated samples proportional to its size. We can show that proportional allocation stratified sampling will be better than simple random sampling in terms of error when the quantity of interest is very homogeneous within each strata.

In the case of stratified sampling, the sample average $\overline{x} \approx \mu_o$ is replaced by the weighted average $\overline{x}_\text{strat} = \sum_{i=1}^k w_i\overline{x}_i$, where $\overline{x}_i$ are strata sample averages. We know that the sample average is an unbiased estimator and by linearity of expectation, so is $\overline{x}_\text{strat}$.

The efficiency (variance) of these estimators, however, differs:

$$Var[\overline{x}] - Var[\overline{x}_\text{strat}] = \frac{1}{n}\sum_{i=1}^k w_i (\mu_i - \mu_0)^2,$$

where $\mu$ is the grand mean and $\mu_i$ are the strata means. TODO: Proof.

Unless all the strata means are exactly the same as the grand mean of the entire population, then the left hand side will be positive, otherwise it will be 0. This implies that proportional stratified sampling is expected to be at least as good as simple random sampling regardless of the data or how we stratify them. This also highlights the goal -- we need strata whose means differ as much as possible from the grand mean. In other words, we want strata with low within-strata variability and high between-strata variability.

Let us simulate the process of drawing our $n =$ `r n` samples `r m` times to check if that is indeed the case. We beleive that Penalty Taking is more in the domain of attacking footballers, so we will stratify based on Best Position:

```{r echo=FALSE}
table(df$BestPosition)
```

Note that in order to do this, we need information like the above about the size of each strata:

```{r echo=FALSE, warning=FALSE, fig.width=2, fig.height=2}
# stratified sampling - proportional

weights <- round(table(df$BestPosition) / nrow(df) * n)
weights[12] <- weights[12] + 2 # a bit of a hack to get exact n

mus <- c()
set.seed(0)
for (i in 1:m) {
  w_mus <- 0
  for (j in 1:length(weights)) {
    tmp <- df$PenaltyTaking[df$BestPosition == names(weights)[j]]
    idx <- sample(1:length(tmp), weights[j], rep = T)
    w_mus <- w_mus + weights[j] / n * mean(tmp[idx])
  }
  mus <- c(mus, w_mus)
}

ggplot(data.frame(mu = mus), aes(x = mu)) + geom_histogram(bins = 30) + 
  ylab("freq") + xlab("estimate")

```

The average over all estimates is `r round(mean(mus), 2)` and their standard deviation is `r round(sd(mus), 3)`. This is better than simple random sampling.

*Optimal allocation*, also known as Neyman allocation is the solution to the optimization problem of finding $n_i$ that minimize the variance of the estimator $\overline{x}_\text{strat}$ estimator:

$$w_i = \frac{n_i}{n} = \frac{N_i\sigma_i}{\sum_{i=1}^k N_i\sigma_i}.$$
We can see that the optimal allocation takes into account strata size and strata homogeneity. The larger the strata and the less homogeneous it is, the more samples we allocate it. The more similar the strata are to the population in terms of variance, the smaller the difference between proportional and optimal allocation:

$$Var[\overline{x}_\text{strat}] - Var[\overline{x}_\text{opt}] = \frac{1}{n}\sum_{i=1}^k w_i (\sigma_i - \sigma_0)^2,$$

where $\sigma_0$ is the grand standard deviation and $\sigma_i$ are the strata standard deviations. TODO: Proof.

Even though optimal location is at least as good as proportional allocation in theory, we might still prefer proportional allocation in practice. Optimal allocation requires a good estimate of the within strata variability $\sigma_i$ which is often unknown, although it can be estimated by preliminary sampling. Also, if we are estimating more than one quantity, the $\sigma_i$ will be different for each quantity and it will be impossible to find an allocation that is optimal for all quantities.

Let us simulate the process of drawing our $n =$ `r n` samples `r m` times to check if that is indeed the case. We beleive that Penalty Taking is more in the domain of attacking footballers, so we will stratify based on Best Position:

```{r echo=FALSE}
table(df$BestPosition)
```

Note that in order to do this, we need information like the above about the size of each strata:

```{r echo=FALSE, warning=FALSE, fig.width=2, fig.height=2}
# stratified sampling - proportional
sds <- tapply(df$PenaltyTaking, df$BestPosition, sd)
weights_opt <- round(n * weights * sds / sum(weights * sds))
weights_opt[12] <- weights_opt[12] - 2 # a bit of a hack to get exact n
mus <- c()
for (i in 1:m) {
  w_mus <- 0
  for (j in 1:length(weights_opt)) {
    tmp <- df$PenaltyTaking[df$BestPosition == names(weights_opt)[j]]
    idx <- sample(1:length(tmp), weights_opt[j], rep = T)
    w_mus <- w_mus + weights[j] / n * mean(tmp[idx])
  }
  mus <- c(mus, w_mus)
}

ggplot(data.frame(mu = mus), aes(x = mu)) + geom_histogram(bins = 30) + 
  ylab("freq") + xlab("estimate")
```

The average over all estimates is `r round(mean(mus), 2)` and their standard deviation is `r round(sd(mus), 3)`. This is better than simple random sampling and proportional stratified sampling.

### Bayesian estimation

```{r echo=FALSE, warning=FALSE, message=FALSE, results = 'hide'}
ml     <- readLines("./stratified2.Stan")
model2 <- stan_model(model_code = ml)

weights <- round(table(df$BestPosition) / nrow(df) * n)
weights[12] <- weights[12] + 2 # a bit of a hack to get exact n
set.seed(0)
res <- NULL

for (i in 1:10) {
  obs <- NULL
    w_mus <- 0
  for (j in 1:length(weights)) {
  
    tmp <- df$PenaltyTaking[df$BestPosition == names(weights)[j]]
    idx <- sample(1:length(tmp), weights[j], rep = T)
    obs <- rbind(obs, data.frame(ID = j, y = tmp[idx]))
    w_mus <- w_mus + weights[j] / n * mean(tmp[idx])
  }
  
  stan_data <- list(y = obs$y, id = obs$ID, n = n, k = length(weights), w = weights / n)
  samples   <- sampling(model2, stan_data, chains = 1, iter = 2000)
  
  mus <- extract(samples)$mu_est
  res <- rbind(res, data.frame(mu = mean(mus),
                               med = median(mus),
                               sd = sd(mus), 
                               w_mus = w_mus,
                               mu_obs = mean(obs$y)))
  
  print(summary(res))
}

```

## Cluster sampling

The cluster sampling scheme is similar to the stratified sampling scheme in that we partition the data into non-overlapping partitions, this time called clusters. However, instead of sampling from all clusters, like we do in stratified sampling, we select at random only a subset of the clusters and then measure all units in the selected clusters. This is called one-stage clustering. Instead of measuring all units in a cluster, we can again estimate the quantity of interest for a cluster using only simple random sample from that cluster. This is called two-stage clustering. The approach can be extend to an arbitrary number of levels and it is called multi-stage clustering.

Cluster sampling is an alternative to simple random sampling and stratified sampling that is used when it is difficult to construct a sampling frame for the entire study population. For example, it would be difficult to get a list of all University of Ljubljana students, but it is relatively easy to get a list of all Faculties and withing each Faculty the list of all study programs. Once a study program is selected, it is easier to establish contact with all students from that program. Cluster sampling is also used to reduce the cost of sampling. For example, if our study involves units that are geographically spread out, it might be cheaper to first select at random only a few geographical locations and then sample from those locations.

Unfortunately, cluster sampling comes at a cost in efficiency. In stratified sampling we benefit from having strata with means that differ as much as possible. We achieve this by having a lot of between-strata variability but little within-strata variability. This very mechanism that benefits us in stratified sampling makes cluster sampling less effective. If we have very little within-cluster variability and a lot of between-cluster variability that will increase the uncertainty of our estimates.

TODO: Proof.

Let us simulate the process of two-stage cluster sampling our $n =$ `r n` samples `r m` times to check if that is indeed the case. We will sample 5 clusters based on Best Position with `r n / 5` simple random samples per cluster:

```{r echo=FALSE, warning=FALSE, fig.width=2, fig.height=2}
h_bootstrap <- function(x, group, w, m = 100) {

  k       <- length(w)
  mus <- c()
  for (i in 1:m) {    # bootstrap iteration
    
    tot_w <- 0
    tot_x <- 0
    for (j in 1:k) {  # resample clusters
      idx <- sample(1:k, 1)
      tmp <- x[group == idx]
      tot_w <- tot_w + w[idx]
      tmp <- sample(tmp, length(tmp), rep = T) # resample withing cluster
      tot_x <- tot_x + mean(tmp) * w[idx]
      
    }
    
    mus <- c(mus, tot_x / tot_w)
  }
  return (list(mu = mean(mus), SE = sd(mus)))
}


library(rstan)
ml     <- readLines("./clustered.Stan")
model2 <- stan_model(model_code = ml)

  
  
# cluster sampling
mus <- c()

weights <- table(df$BestPosition) / nrow(df) 

bp <- unique(df$BestPosition)


res <- NULL
for (i in 1:m) {
  x_total <- 0
  w_total <- 0
  all_y   <- c()
  all_g   <- c()
  all_w   <- c()
  for (j in 1:5) {
    idw <- sample(1:length(bp), 1)
    tmp <- df$PenaltyTaking[df$BestPosition == bp[idw]]
    idx <- sample(1:length(tmp), n / 5, rep = T)
    all_y <- c(all_y, tmp[idx])
    all_g <- c(all_g, rep(j, length(idx)))
    all_w <- c(all_w, weights[idw])
    x_total <- x_total + weights[idw] * mean(tmp[idx])
    w_total <- w_total + weights[idw]
  }

  mus <- c(mus, x_total / w_total)
  bts <- h_bootstrap(all_y, all_g, all_w)
  
  stan_data <- list(y = all_y, id = all_g, n = length(all_y), k = length(all_w), w = all_w / sum(all_w))
  samples   <- sampling(model2, stan_data, chains = 1, iter = 2000)

  
  res <- rbind(res, data.frame(mu = x_total / w_total,
                               mu_simple = mean(all_y),
                               se_simple = sd(all_y) / sqrt(n),
                               mu_boot = bts$mu,
                               se_boot = bts$SE,
                               mu_bayes = mean(extract(samples)$mu_est),
                               se_bayes = sd((extract(samples)$mu_est))))
}

ggplot(data.frame(mu = mus), aes(x = mu)) + geom_histogram(bins = 30) + 
  ylab("freq") + xlab("estimate")

```

The average over all estimates is `r round(mean(mus), 2)` and their standard deviation is `r round(sd(mus), 3)`. This is worse than simple random sampling.

# Non-probability sampling schemes 

We have already defined non-probability sampling as a sampling approach where some elements of the population have no chance of selection or where we cannot determine the probability of selection. Another way of looking at non-probability sampling is as the sampling approach that we use when no probability sampling approach is feasible. This is typically due to not being able to create a sampling frame. For example, it is impossible to create a sampling frame for all dung beetles and some subpopulations, such as drug additcs are difficult to reach. Instead of random sampling, we select elements based on other criteria and assumptions regarding the study population. This gives rise to exclusion bias, placing limits on the representativeness of the sample. While the results of non-probability sample might be useful in some cases, it is in most cases impossible to make any scientifically sound generalizations to the study population.

## Convenience sampling

Convenience sampling is also known as opportunity sampling or accidental sampling. It is a type of non-probability sampling where the main criterion for selection is that the units are close at hand. An example of convenience sampling would be if we did a statistical enquiry of University of Ljubljana students and only include students from this Bayesian statistics class.

## Judgement sampling

Judgement sampling is also known as purposive sampling or authoritative sampling. It is a type of non-probability sampling where the researchers choose the sample based on their expert knowledge of what would be a representative sample. The criteria we use depend on the context:

* If the goal is to capture the extremes of the variability of some property of our study units, we will select a sample that is diverse with respect to some other variates. That is, samples that are as different from eachother as possible. This is also known as maximum variation sampling. For example, when selecting problems for the course exam, we try to select problems that cover the entire subject matter.

* If the goal is to investigate how a particular property, we will select units that are as similar as possible in all other traits. This is also known as homogeneous sampling. For example, if we are interested in long-term effects of working with a hazardous material, we would select people that are as similar as possible in every other aspect including working with that material for a long time.

* If the goal is to investigate what is typical or atypical, we will select a sample of units that are most or least similar to what is considered typical. This is also known as typical/atypical case sampling. For example, if we are investigating how a typical Faculty of computer information student rates the study program, we would immediately exclude exchange students, female students, students from joint study programs with other Faculties, etc.

## Quota sampling

Quota sampling is similar to stratified sampling in that we first partition the study population into non-overlapping partitions based on characteristics we believe are good at explaining the variability in the variates of interest. For each strata we then determine the number of samples we require for that strata -- that is, the quota. This might be based on known or approximate proportions of those strata in the study population. The difference between quota and stratified sampling is that in quota sampling we then proceed by meeting the quota of samples by non-probability approaches such as convenience or judgement sampling.

For example, if we were interested in some characteristic of University of Ljubljana students, we might stratify the students based on Faculty, sex, and year of study and then try to find at least 3 students from each strata.

## Snowball sampling

Snowball sampling is a non-probability sampling scheme that is based on peoples social networks. In its most basic form snowball sampling starts with an initial set of eligible subjects and then each subject is asked to suggest all eligible subjects from their social network (friends, family members, acquaintances). This process is stopped when we have a large enough sample or when no new eligible subjects are found.

Snowball sampling has many sources of bias, including the selection of initial set of subjects and biases from how people suggest new eligible subjects. However, in some cases snowball sampling is the only option we have. For example, when dealing with sensitive topics and hidden populations, such as drug addicts, prostitutes, or experts in narrow scientific fields. In such cases there is no readily available sampling frame but if we find a few eligible subjects, it is very likely that they know several other eligible subjects.

Snowball sampling is one of the few non-probability sampling methods for which some rigorous results are available. A variant of snowball sampling called respondent-driven sampling will, under certain assumptions on the properties of the social network and the recruitement proces, provide unbiased estimates.

# Recommended readings

* Thompson, S. K. (2012) Sampling, Third Edition. (Chapters 1, 11, 12)

# Additional readings

* Salganik, M. J., & Heckathorn, D. D. (2004). Sampling and estimation in hidden populations using respondent-driven sampling. Sociological methodology, 34(1), 193-240.

# Homework

TODO?
